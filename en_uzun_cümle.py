# -*- coding: utf-8 -*-
"""en_uzun_cümle

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h3KUfD91HTxX-HIvOnEtlTt4vvMyGWSR
"""

import pandas as pd
import numpy as np
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation
from keras.layers.embeddings import Embedding

train=pd.read_excel("clean_tweet_train.xlsx")
test=pd.read_excel("clean_tweet_test.xlsx")

Train = train.append(test, ignore_index=True).fillna(' ')
type(Train.text.tolist())
Train.head()

lenght=[]
mx=len(Train['text'][0])
index=0
for i in range(1,len(Train)):
      if mx<len(Train['text'][i]):
         mx=len(Train['text'][i])
         index=i
          
print("veri setindeki en uzun cümle:")
print(Train['text'][index].split())
print("padding için kullanılacak maksimum kelime sayısı:",len(Train['text'][index].split()))
print("index:",index)



